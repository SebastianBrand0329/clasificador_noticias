# --------------------------------------------------------------------------
# app.py - Aplicaci√≥n simple de clasificaci√≥n de noticias con Streamlit y Gemini
# --------------------------------------------------------------------------

# 1. Importar las librer√≠as necesarias
import streamlit as st
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --------------------------------------------------------------------------
# CONFIGURACI√ìN DE LA P√ÅGINA Y LA API KEY
# --------------------------------------------------------------------------

# T√≠tulo de la aplicaci√≥n que se mostrar√° en la pesta√±a del navegador
st.set_page_config(page_title="Clasificador de Noticias", page_icon="üì∞")

# T√≠tulo principal de la aplicaci√≥n
st.title("üì∞ Clasificador de Noticias con Gemini")
st.caption("Pega el texto de una noticia y obt√©n su categor√≠a estimada.")

# Configuraci√≥n de la API Key de Google de forma segura
try:
    os.environ['GOOGLE_API_KEY'] = st.secrets['AIzaSyA4sQCZpJaV-xPvqxjQy1EUg1nQlBzOlpE']
except:
    st.info("API Key no encontrada en los secrets. Aseg√∫rate de configurar tu archivo secrets.toml.")

# --------------------------------------------------------------------------
# COMPONENTES DE LANGCHAIN Y L√ìGICA DEL MODELO
# --------------------------------------------------------------------------

# 1. Plantilla del Prompt
prompt = ChatPromptTemplate.from_template(
    """
    Eres un clasificador experto de noticias. 
    Tu tarea es leer el texto de una noticia y asignarle una categor√≠a.

    Las categor√≠as posibles son:
    - pol√≠tica
    - deportes
    - econom√≠a
    - tecnolog√≠a
    - salud
    - cultura
    - internacional
    - otra

    Noticia:
    {news_text}

    Devuelve SOLO la categor√≠a, sin explicaci√≥n.
    """
)

# 2. Instancia del modelo Gemini
llm = ChatGoogleGenerativeAI(model="gemini-2.5-pro", temperature=0.0)

# 3. Parser de salida
parser = StrOutputParser()

# 4. Crear la cadena de ejecuci√≥n
chain = prompt | llm | parser

# --------------------------------------------------------------------------
# INTERFAZ DE USUARIO DE STREAMLIT
# --------------------------------------------------------------------------

# √Årea de texto para pegar la noticia
news_text = st.text_area(
    "Pega aqu√≠ el texto de la noticia:",
    placeholder="Escribe o pega el contenido completo de la noticia..."
)

# Bot√≥n de clasificaci√≥n
if st.button("Clasificar"):
    if news_text.strip() == "":
        st.warning("Por favor ingresa el texto de una noticia.")
    else:
        with st.spinner("Clasificando noticia... üß†"):
            try:
                # Ejecutamos el modelo
                result = chain.invoke({"news_text": news_text})

                # Mostrar resultado
                st.markdown("### üè∑Ô∏è Categor√≠a predicha:")
                st.markdown(f"**{result}**")

            except Exception as e:
                st.error(f"Ocurri√≥ un error al procesar la noticia: {e}")
